# -*- coding: utf-8 -*-
"""edge_labeling_00.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mFeONWk9--IWiYRSGu9r5nogh9iFm4iW
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import spacy
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF

df = pd.read_csv('/content/drive/MyDrive/sample_emails (1).csv')
df.drop(columns='file', inplace=True)

data = df.copy()

def target_extraction(string: str):
    text = string.splitlines()
    text = text[:text.index('')]
    has_to = False
    idx_start = None
    idx_end = None

    for line in text:
        if line[:3] == 'To:':
            # print(line)
            has_to = True
            idx_start = text.index(line)
        elif line[:8] == 'Subject:':
            idx_end = text.index(line)

    if has_to:
        res = ' '.join(text[idx_start:idx_end])
        return [i.strip() for i in res[3:].split(',')]
    else:
        return np.nan

def source_extraction(string: str):
    text = string.splitlines()
    text = text[:text.index('')]
    has_to = False
    idx_start = None
    idx_end = None

    for line in text:
        if line[:3] == 'To:':
            # print(line)
            has_to = True
        elif line[:5] == 'From:':
            idx_start = text.index(line)

    if has_to:
        for line in text:
            if line[:3] == "To:":
                idx_end = text.index(line)
    else:
        for line in text:
            if line[:8] == 'Subject:':
                idx_end = text.index(line)


    res = ' '.join(text[idx_start:idx_end])
    return [i.strip() for i in res[5:].split(',')]

def text_extraction(string: str):
    text = string.splitlines()
    text = text[text.index(''):]

    return ' '.join(text)

data['source'] = data['message'].apply(lambda x: source_extraction(x))
data['target'] = data['message'].apply(lambda x: target_extraction(x))
data['email']  = data['message'].apply(lambda x: text_extraction(x))

data.dropna(inplace=True)

data = data.explode('source', ignore_index=True)
data = data.explode('target', ignore_index=True)

data.reset_index(inplace=True)
data.drop(columns=['index', 'Unnamed: 0', 'message'], inplace=True)

nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])

def preprocess_text(in_text):
    doc = nlp(in_text)

    tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop and not token.is_punct]
    text = ' '.join(tokens)
data
    return text

data['text'] = data['email'].apply(lambda x: preprocess_text(x))

data

n_topics = 5

text_vectorizer = TfidfVectorizer(stop_words='english')
X = text_vectorizer.fit_transform(data['text'])

model_nmf = NMF(n_components=n_topics, random_state=0)
model_nmf.fit(X)

topics = {}
for idx, topic in enumerate(model_nmf.components_):
    topics[idx] = [text_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-5:]]
topics

result = model_nmf.transform(X)
data['label'] = result.argmax(axis=1)

data

data.drop(columns=['email', 'text'], inplace=True)

data.to_csv('/content/drive/MyDrive/Enron_Project/edge_labeling_00_result.csv')

