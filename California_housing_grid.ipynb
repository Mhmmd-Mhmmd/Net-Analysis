{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMSDXIbz7gxurE/uDG+lgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mhmmd-Mhmmd/Net-Analysis/blob/main/California_housing_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBeuy0Et8yf_"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as k\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "california_housing = fetch_california_housing()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(california_housing['data'],\n",
        "                                                    california_housing['target'])\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train = sc.transform(X_train)\n",
        "X_valid = sc.transform(X_valid)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "0ZQo4qm9_mKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = k.callbacks.ModelCheckpoint('model_chechpoints_cal_house_reg_func.h5',\n",
        "                                                        save_best_only=True, # it means instead of saving all models only save best one since\n",
        "                                                       )\n",
        "early_stopping_callbacks = k.callbacks.EarlyStopping(patience=50,\n",
        "                                                     restore_best_weights=True\n",
        "                                                    )\n",
        "tb_callback = k.callbacks.TensorBoard('tb_logs') # it's a relative address whitch means here in this very same directory make a new one\n"
      ],
      "metadata": {
        "id": "Sk-U72i4ANRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ann_model(\n",
        "    number_hidden_layers = 1,\n",
        "    number_neurons = 50,\n",
        "    lr=0.1):\n",
        "  model = k.models.Sequential()\n",
        "  model.add(k.layers.InputLayer(input_shape=X_train.shape[1:]))\n",
        "  for num in range(number_hidden_layers):\n",
        "    model.add(k.layers.Dense(number_neurons, activation='selu'))\n",
        "  model.add(k.layers.Dense(1, activation='relu'))\n",
        "\n",
        "  sgd = k.optimizers.SGD(lr=lr)\n",
        "  model.compile(\n",
        "      loss='mse',\n",
        "      optimizer=sgd\n",
        "\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "uHmjqCXzAph2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_skl_reg = k.wrappers.scikit_learn.KerasRegressor(build_fn=ann_model)\n",
        "\n",
        "param_grid = {'number_hidden_layers' : [1, 3, 5],\n",
        "              'number_neurons' : [50, 100, 150],\n",
        "              'lr' : [0.1, 0.01, 0.001]\n",
        "\n",
        "}\n",
        "\n",
        "keras_skl_reg_gs = GridSearchCV(keras_skl_reg, param_grid=param_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMDFc607BCEU",
        "outputId": "5a3a9918-b11b-4c1f-c947-98d42a2d5f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_skl_reg_gs.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=[X_valid, y_valid],\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm3rJX-VEZ7-",
        "outputId": "ce43dd2c-dc85-4ae4-d362-741748da1200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 4s 5ms/step - loss: 0.5802 - val_loss: 0.6467\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 2s 6ms/step - loss: 0.4782 - val_loss: 0.5887\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4607 - val_loss: 0.4168\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4529 - val_loss: 0.4944\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4509 - val_loss: 0.6141\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6361\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5929 - val_loss: 0.6953\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4702 - val_loss: 0.4515\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4587 - val_loss: 0.4790\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4523 - val_loss: 0.4999\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4460 - val_loss: 0.5298\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5606\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5841 - val_loss: 0.6593\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4763 - val_loss: 0.6434\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4640 - val_loss: 0.4306\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4592 - val_loss: 0.4503\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4500 - val_loss: 0.4178\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4413\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6102 - val_loss: 0.6269\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4879 - val_loss: 0.5222\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4695 - val_loss: 0.4207\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4573 - val_loss: 0.4471\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 0.5580\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5712\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5813 - val_loss: 0.4753\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4808 - val_loss: 0.4906\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4680 - val_loss: 0.5739\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4658 - val_loss: 0.4226\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4519 - val_loss: 0.4399\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4313\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.9845 - val_loss: 178.6660\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5700 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 5.7146\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6000 - val_loss: 0.6622\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4781 - val_loss: 0.5983\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4653 - val_loss: 0.4969\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4458 - val_loss: 0.4052\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4464 - val_loss: 0.4443\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4956\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5960 - val_loss: 0.7064\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4782 - val_loss: 0.6147\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4538 - val_loss: 0.4360\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4553 - val_loss: 0.4930\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4457 - val_loss: 0.5587\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5931\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5850 - val_loss: 0.4732\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4851 - val_loss: 0.4903\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4679 - val_loss: 0.4984\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4605 - val_loss: 0.4785\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4625\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4437\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6025 - val_loss: 0.4872\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4919 - val_loss: 0.5156\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4663 - val_loss: 0.9322\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4612 - val_loss: 0.4866\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4588 - val_loss: 0.5701\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5880\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5921 - val_loss: 0.4561\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4718 - val_loss: 0.6004\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4568 - val_loss: 0.4890\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4455 - val_loss: 0.5269\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4489 - val_loss: 0.5161\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5513\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5681 - val_loss: 0.9072\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4791 - val_loss: 0.4760\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4571 - val_loss: 0.6013\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5165 - val_loss: 0.5528\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4465 - val_loss: 0.4470\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4869\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5999 - val_loss: 0.7425\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4754 - val_loss: 0.5907\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4639 - val_loss: 0.5256\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4514 - val_loss: 0.7374\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4446 - val_loss: 0.4109\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4545\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5942 - val_loss: 0.4351\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4843 - val_loss: 0.4726\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4703 - val_loss: 0.4571\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4611 - val_loss: 0.4709\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.5041\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4928\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6040 - val_loss: 0.5815\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4825 - val_loss: 0.5328\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4654 - val_loss: 0.4337\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.5029\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4555 - val_loss: 0.5264\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5196\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 49201392.0000 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 5.7146\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 808.0768 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5763\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 24.5913 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4540\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 3ms/step - loss: 241.7887 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4716\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 5293.0776 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5725\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
            "73/73 [==============================] - 0s 1ms/step - loss: nan\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 186.0727 - val_loss: 189339435008.0000\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 189339435008.0000\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 189339435008.0000\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5532 - val_loss: 189339435008.0000\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5532 - val_loss: 189339435008.0000\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 293187158016.0000\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1716739456.0000 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 5.4540\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "73/73 [==============================] - 0s 2ms/step - loss: nan\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 72401.8359 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 5.5725\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 5.7616 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.7146\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 9140.1836 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5763\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 59.9320 - val_loss: 72855872.0000\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 72855872.0000\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 72855872.0000\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 72855872.0000\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 5.5837 - val_loss: 72855872.0000\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 5.4540\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 20.5206 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4716\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 1151398144.0000 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5725\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 6.5659 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 5.7146\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 17.4850 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5763\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2960.9404 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "73/73 [==============================] - 0s 2ms/step - loss: nan\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 9.8219 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5725\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "73/73 [==============================] - 0s 2ms/step - loss: nan\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 324.5806 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5763\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 27.2410 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4540\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 19016.2305 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4716\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 40.1998 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5725\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 219086.1406 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5186 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.7146\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 8407.8721 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 5.5532 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5763\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 2083.7898 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5837 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4540\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 14490.7842 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5793 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.4716\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 8511.0137 - val_loss: 5.6856\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 5.5541 - val_loss: 5.6856\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 5.5725\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.7319 - val_loss: 0.4681\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4639 - val_loss: 0.4647\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4557 - val_loss: 0.4346\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.4380\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4432 - val_loss: 0.4355\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4608\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6372 - val_loss: 0.4630\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4537 - val_loss: 0.4353\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4461 - val_loss: 0.4335\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4396 - val_loss: 0.4407\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4335 - val_loss: 0.4384\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4755\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6860 - val_loss: 0.4667\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4652 - val_loss: 0.4429\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4571 - val_loss: 0.4380\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4514 - val_loss: 0.4317\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4468 - val_loss: 0.4314\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4584\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.7207 - val_loss: 0.4565\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4723 - val_loss: 0.4563\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4641 - val_loss: 0.4403\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4585 - val_loss: 0.4572\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4536 - val_loss: 0.4482\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4410\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.8054 - val_loss: 0.4598\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4732 - val_loss: 0.4581\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4616 - val_loss: 0.4321\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4556 - val_loss: 0.4409\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4513 - val_loss: 0.4250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4167\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6914 - val_loss: 0.4563\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4592 - val_loss: 0.4398\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4508 - val_loss: 0.4404\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 0.4297\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4385 - val_loss: 0.4219\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4504\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6879 - val_loss: 0.4756\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4506 - val_loss: 0.4326\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4419\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4377 - val_loss: 0.4264\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4309 - val_loss: 0.4228\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4629\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.7042 - val_loss: 0.4545\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4649 - val_loss: 0.4374\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4598 - val_loss: 0.4543\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4469 - val_loss: 0.4294\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4386 - val_loss: 0.4430\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4664\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6301 - val_loss: 0.5103\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4397\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4609 - val_loss: 0.4406\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4553 - val_loss: 0.4685\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4503 - val_loss: 0.4496\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4364\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.8079 - val_loss: 0.4520\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4737 - val_loss: 0.4448\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4589 - val_loss: 0.4536\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4497 - val_loss: 0.4305\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4264\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4190\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6725 - val_loss: 0.4421\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4547 - val_loss: 0.5063\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4487 - val_loss: 0.4592\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4419 - val_loss: 0.4355\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4371 - val_loss: 0.4291\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4595\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.7041 - val_loss: 0.4871\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4775 - val_loss: 0.4403\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4500 - val_loss: 0.4501\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4432 - val_loss: 0.4294\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4370 - val_loss: 0.4400\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4732\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6009 - val_loss: 0.4591\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4587 - val_loss: 0.4453\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4524 - val_loss: 0.4444\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4444 - val_loss: 0.4295\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4381 - val_loss: 0.4254\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4515\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6184 - val_loss: 0.4501\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4682 - val_loss: 0.4473\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4586 - val_loss: 0.4297\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4500 - val_loss: 0.4682\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4451 - val_loss: 0.4232\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4200\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 0.7023 - val_loss: 0.4383\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4582 - val_loss: 0.4356\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4518 - val_loss: 0.4413\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4465 - val_loss: 0.4210\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4146\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4102\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5205 - val_loss: 0.4542\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4156 - val_loss: 0.4582\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.5285\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.3811\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3703 - val_loss: 0.3846\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4131\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5702 - val_loss: 2.1304\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4246 - val_loss: 0.4237\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.3922\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 1.8327\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3773 - val_loss: 0.4288\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4821\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.7078 - val_loss: 0.5033\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4541 - val_loss: 0.4423\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4323 - val_loss: 0.4046\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.4130\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.3882\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4165\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5724 - val_loss: 0.4326\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4011\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.3991\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4006 - val_loss: 0.3643\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.3906 - val_loss: 0.4848\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4695\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6211 - val_loss: 0.8315\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4482 - val_loss: 0.4429\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4257\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4075 - val_loss: 0.3922\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3914 - val_loss: 0.5403\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5398\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.5522 - val_loss: 0.4657\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4391 - val_loss: 0.4302\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4151 - val_loss: 0.4092\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4082 - val_loss: 0.4849\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.3950\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4192\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5955 - val_loss: 0.4251\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4323 - val_loss: 0.4195\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4042\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.3863\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4477\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4836\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5502 - val_loss: 0.7256\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4400 - val_loss: 0.5559\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 0.4928\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4200\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4052\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4396\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5372 - val_loss: 0.4388\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4378 - val_loss: 0.4554\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.6807\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.6719\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.3539\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3426\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.5784 - val_loss: 0.5173\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4446 - val_loss: 0.4523\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4250 - val_loss: 0.4181\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 0.4053\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3982 - val_loss: 0.3993\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4044\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.5716 - val_loss: 0.4309\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4272 - val_loss: 0.4419\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.7181\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3937 - val_loss: 0.5820\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3840 - val_loss: 0.3982\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4401\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.5621 - val_loss: 0.4888\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4264 - val_loss: 0.5260\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.3921\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.5598\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3823 - val_loss: 0.5766\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5933\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5602 - val_loss: 0.4969\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4343 - val_loss: 0.4332\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.5297\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.3711\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3870 - val_loss: 0.3909\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4192\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.5618 - val_loss: 0.5249\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4408 - val_loss: 0.4018\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4257\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4096 - val_loss: 0.3800\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.3898\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3730\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6513 - val_loss: 0.6119\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4392 - val_loss: 0.5328\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4126 - val_loss: 0.5558\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.6324\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4302\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4312\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5501 - val_loss: 0.3698\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3906 - val_loss: 0.4236\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.3421\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3651 - val_loss: 0.7212\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.5290\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5539\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.5221 - val_loss: 0.5425\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.3575\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.3347\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3547 - val_loss: 0.3916\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3417 - val_loss: 1.1298\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4979\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5841 - val_loss: 0.8195\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.7388\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.4131\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.8164\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.6064\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3554\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 3ms/step - loss: 0.5744 - val_loss: 0.4692\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.4343\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.3899\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3843 - val_loss: 0.3492\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3718 - val_loss: 0.3292\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3179\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.6264 - val_loss: 0.4588\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4009\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3750 - val_loss: 0.4091\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4613\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.3519 - val_loss: 0.3303\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3386\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6056 - val_loss: 0.5410\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 0.4172\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3787 - val_loss: 0.4934\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4043\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.4116\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4458\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5733 - val_loss: 0.5997\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4062\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3739 - val_loss: 0.4105\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3637 - val_loss: 0.4501\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3523 - val_loss: 0.6285\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.6275\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.5800 - val_loss: 0.5343\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4151 - val_loss: 0.3814\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3881 - val_loss: 0.8928\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.5329\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3601 - val_loss: 0.5533\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5634\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.5900 - val_loss: 0.3737\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4105 - val_loss: 0.4253\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.4054\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3789 - val_loss: 0.4829\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.3301\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3255\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.5718 - val_loss: 0.4162\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4505\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3790 - val_loss: 0.3877\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3667 - val_loss: 0.9666\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4445\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4492\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.5958 - val_loss: 0.4441\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4122\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3778 - val_loss: 1.2632\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3702 - val_loss: 0.5389\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3575 - val_loss: 1.0146\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1.0055\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.6176 - val_loss: 0.4480\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4091 - val_loss: 0.4502\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.3836 - val_loss: 0.3443\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3653\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3496 - val_loss: 0.4229\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4681\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.5613 - val_loss: 0.4807\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4046 - val_loss: 0.5061\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3742 - val_loss: 0.6808\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3626 - val_loss: 0.4284\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4113\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4399\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.7379 - val_loss: 0.5803\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4177 - val_loss: 0.5168\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3976 - val_loss: 0.4481\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3780 - val_loss: 0.3400\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.3620 - val_loss: 0.3499\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3427\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.5999 - val_loss: 0.5482\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.4209 - val_loss: 0.7628\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3872 - val_loss: 0.5366\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3697 - val_loss: 0.6883\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.3628 - val_loss: 0.4617\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4755\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 1.0122\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.7238 - val_loss: 0.5831\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.5364\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5376 - val_loss: 0.5096\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5151 - val_loss: 0.4923\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5265\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2.4943 - val_loss: 1.5029\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.7019 - val_loss: 0.5201\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5045 - val_loss: 0.4895\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4845 - val_loss: 0.4816\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4772 - val_loss: 0.4745\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.5091\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 2.5702 - val_loss: 0.9494\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6172 - val_loss: 0.4933\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4908 - val_loss: 0.4713\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4779 - val_loss: 0.4622\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4716 - val_loss: 0.4577\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4857\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2.9732 - val_loss: 0.8011\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6015 - val_loss: 0.5148\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5231 - val_loss: 0.4865\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5047 - val_loss: 0.4736\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4940 - val_loss: 0.4637\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4549\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 1.9280 - val_loss: 0.6614\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6337 - val_loss: 0.5607\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5777 - val_loss: 0.5260\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5455 - val_loss: 0.5000\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5202 - val_loss: 0.4807\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4728\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 2ms/step - loss: 2.4729 - val_loss: 0.7650\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5850 - val_loss: 0.5064\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5055 - val_loss: 0.4779\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4861 - val_loss: 0.4654\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4758 - val_loss: 0.4569\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4890\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2.2915 - val_loss: 0.7764\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.5173\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5124 - val_loss: 0.4878\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4886 - val_loss: 0.4709\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4745 - val_loss: 0.4591\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4972\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 3.1095 - val_loss: 2.2858\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 1.0504 - val_loss: 0.5179\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5121 - val_loss: 0.4795\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4872 - val_loss: 0.4624\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4732 - val_loss: 0.4541\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4851\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1.8552 - val_loss: 0.6574\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6268 - val_loss: 0.5642\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5714 - val_loss: 0.5237\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5375 - val_loss: 0.4975\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5131 - val_loss: 0.4771\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.4730\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2.2276 - val_loss: 0.6551\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5705 - val_loss: 0.5042\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5122 - val_loss: 0.4761\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4911 - val_loss: 0.4625\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4798 - val_loss: 0.4533\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4446\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2.2282 - val_loss: 0.7049\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5872 - val_loss: 0.5203\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5205 - val_loss: 0.4863\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4923 - val_loss: 0.4642\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4730 - val_loss: 0.4509\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4826\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 2.2819 - val_loss: 0.6614\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5777 - val_loss: 0.5210\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5187 - val_loss: 0.4898\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4933 - val_loss: 0.4714\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4783 - val_loss: 0.4611\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.5019\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1.4222 - val_loss: 0.5280\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5185 - val_loss: 0.4819\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4891 - val_loss: 0.4620\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4743 - val_loss: 0.4517\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4659 - val_loss: 0.4456\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4756\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1.5106 - val_loss: 0.5333\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5368 - val_loss: 0.4894\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5051 - val_loss: 0.4700\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4880 - val_loss: 0.4572\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4776 - val_loss: 0.4502\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4430\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1.8194 - val_loss: 0.5735\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5711 - val_loss: 0.5137\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 0.4857\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5018 - val_loss: 0.4659\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4841 - val_loss: 0.4548\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4498\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1.3054 - val_loss: 0.6103\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5138 - val_loss: 0.8064\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4780 - val_loss: 1.5519\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4617 - val_loss: 1.6149\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4507 - val_loss: 2.4757\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4647\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1.0981 - val_loss: 0.5150\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4858 - val_loss: 0.4673\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4604 - val_loss: 0.4504\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4485 - val_loss: 0.4384\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4411 - val_loss: 0.4332\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4613\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 1.0335 - val_loss: 0.5003\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4982 - val_loss: 0.4774\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4783 - val_loss: 0.4579\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4474\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4552 - val_loss: 0.4378\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4624\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 1.2820 - val_loss: 0.5418\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5332 - val_loss: 0.4872\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 0.4639\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4845 - val_loss: 0.4529\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4730 - val_loss: 0.4455\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4411\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 3ms/step - loss: 1.3796 - val_loss: 0.5296\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5218 - val_loss: 0.4749\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4867 - val_loss: 0.4557\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4713 - val_loss: 0.4449\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4618 - val_loss: 0.4357\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4335\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 1.9939 - val_loss: 0.5433\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4996 - val_loss: 0.4979\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4676 - val_loss: 0.4643\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4547 - val_loss: 0.4437\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4439 - val_loss: 0.4440\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4615\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.8741 - val_loss: 0.4926\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4812 - val_loss: 0.4586\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4608 - val_loss: 0.4430\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4484 - val_loss: 0.4353\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4389 - val_loss: 0.4243\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4675\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 1.0085 - val_loss: 0.4844\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4879 - val_loss: 0.4717\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4707 - val_loss: 0.4523\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4591 - val_loss: 0.4447\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4498 - val_loss: 0.4400\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4632\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.8332 - val_loss: 0.4593\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4725 - val_loss: 0.4413\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4578 - val_loss: 0.4327\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4459 - val_loss: 0.4203\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4256\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4107\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 1.0397 - val_loss: 0.4808\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4805 - val_loss: 0.4413\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4570 - val_loss: 0.4307\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4438 - val_loss: 0.4228\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4339 - val_loss: 0.4137\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4094\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.9775 - val_loss: 0.4618\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4583 - val_loss: 0.4384\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4416 - val_loss: 0.4252\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4311 - val_loss: 0.4191\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4211 - val_loss: 0.4117\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4315\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.9805 - val_loss: 0.4552\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4502 - val_loss: 0.4308\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4346 - val_loss: 0.4171\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4234 - val_loss: 0.4110\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4015\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4365\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.8247 - val_loss: 0.4604\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4543 - val_loss: 0.4328\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4388 - val_loss: 0.4247\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4286 - val_loss: 0.4145\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.4077\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4306\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.8453 - val_loss: 0.4477\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4562 - val_loss: 0.4300\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4433 - val_loss: 0.4323\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4335 - val_loss: 0.4147\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4258 - val_loss: 0.4103\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4013\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.9050 - val_loss: 0.4722\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4711 - val_loss: 0.4358\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4529 - val_loss: 0.4237\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4418 - val_loss: 0.4196\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4333 - val_loss: 0.4109\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4101\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 1.1030 - val_loss: 0.4835\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4672 - val_loss: 0.4435\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4415 - val_loss: 0.4251\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4248 - val_loss: 0.4100\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4030\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4261\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 1.0984 - val_loss: 2.6386\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4807 - val_loss: 2.9790\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4424 - val_loss: 3.4812\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 3.0781\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 2.9241\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4329\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.8728 - val_loss: 0.4975\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.4539\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4540 - val_loss: 0.4289\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4326 - val_loss: 0.4150\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4143\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4428\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 1.1730 - val_loss: 0.5280\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5082 - val_loss: 0.5172\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4750 - val_loss: 0.4627\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4397\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.4231\n",
            "73/73 [==============================] - 0s 1ms/step - loss: 0.3957\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 3ms/step - loss: 0.7645 - val_loss: 0.4638\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4718 - val_loss: 0.4354\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4487 - val_loss: 0.4159\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4075\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4027\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4094\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 1.1939 - val_loss: 0.4643\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4518 - val_loss: 0.4270\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4231 - val_loss: 0.4308\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.3869\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.3961\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4147\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.6858 - val_loss: 0.4678\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4533 - val_loss: 0.4379\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4284 - val_loss: 0.4075\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4114 - val_loss: 0.4073\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.4159\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4537\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 4ms/step - loss: 0.8348 - val_loss: 0.4624\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4537 - val_loss: 0.4257\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4058\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.3924\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3885 - val_loss: 0.3864\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4189\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.8219 - val_loss: 0.4486\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4437 - val_loss: 0.4195\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4129 - val_loss: 0.5431\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3966 - val_loss: 0.3737\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3830 - val_loss: 0.4060\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3913\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 1s 3ms/step - loss: 0.6862 - val_loss: 0.4512\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4526 - val_loss: 0.4291\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4261 - val_loss: 0.4017\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.3926\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3964 - val_loss: 0.4212\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4185\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.6619 - val_loss: 0.5083\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4352 - val_loss: 0.4153\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4008\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3947 - val_loss: 0.3882\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3833 - val_loss: 0.3727\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4079\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.7449 - val_loss: 0.4388\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.4315 - val_loss: 0.4215\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.4088 - val_loss: 0.3909\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3927 - val_loss: 0.3943\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3780 - val_loss: 0.3967\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4263\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 4ms/step - loss: 0.7059 - val_loss: 0.4596\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4266 - val_loss: 0.4104\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3996 - val_loss: 0.3858\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3843 - val_loss: 0.3697\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.3710 - val_loss: 0.4088\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4282\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.6916 - val_loss: 0.4278\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.4318 - val_loss: 0.3927\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.4050 - val_loss: 0.4133\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3913 - val_loss: 0.4383\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.3818 - val_loss: 0.3785\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.3694\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 [==============================] - 2s 5ms/step - loss: 0.6276 - val_loss: 0.4426\n",
            "Epoch 2/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.4438 - val_loss: 0.4173\n",
            "Epoch 3/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.4174 - val_loss: 0.4072\n",
            "Epoch 4/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.3991 - val_loss: 0.3816\n",
            "Epoch 5/5\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.3863 - val_loss: 0.4000\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.4006\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-0.52811314 -1.56698546 -0.50101401 -5.55780001         nan -5.55780001\n",
            "         nan         nan -5.55780001 -0.45048036 -0.44702939 -0.44287687\n",
            " -0.46421203 -0.41789714 -0.45138301 -0.41273755 -0.48227758 -0.54632314\n",
            " -0.48978152 -0.47778447 -0.47058177 -0.45258228 -0.4424529  -0.42202035\n",
            " -0.42137899 -0.41943106 -0.40648534]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5174 - val_loss: 0.4196\n",
            "Epoch 2/5\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4224 - val_loss: 0.3893\n",
            "Epoch 3/5\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3995 - val_loss: 0.3791\n",
            "Epoch 4/5\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3846 - val_loss: 0.3615\n",
            "Epoch 5/5\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3709 - val_loss: 0.3578\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc4df310b50>,\n",
              "             param_grid={'lr': [0.1, 0.01, 0.001],\n",
              "                         'number_hidden_layers': [1, 3, 5],\n",
              "                         'number_neurons': [50, 100, 150]})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_skl_reg_gs.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwDjvDPzFD4u",
        "outputId": "1d290201-1c73-4b6e-bdf9-a4475d5cf675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lr': 0.001, 'number_hidden_layers': 5, 'number_neurons': 150}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_skl_reg_gs.best_estimator_.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obdhn1TMkklt",
        "outputId": "9da5a960-1cbd-4722-be42-345c05e52144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7fc4dfd34110>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = keras_skl_reg_gs.best_estimator_.model"
      ],
      "metadata": {
        "id": "fceJbyymlW3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.evaluate(X_test,\n",
        "                     y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIdIp4TPlp1J",
        "outputId": "64324778-04d0-4b17-a843-ac8ac00310d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3534\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3534289598464966"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# fmnist_data = k.datasets.fashion_mnist\n",
        "# (x_train, y_train), (x_test, y_test) = fmnist_data.load_data()\n",
        "plt.imshow(k.datasets.fashion_mnist.load_data()[0][0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Bs57Y1H7ma8M",
        "outputId": "ed4245a7-1c7b-4070-ef96-26f4fdb71fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc4dfed50d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras as k\n",
        "from sklearn.preprocessing import OneHotEncoder #StandardScaler, Normalizer, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "ZfcIdiYepTUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NrKiNrMOYYuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = k.datasets.cifar10.load_data()\n",
        "\n",
        "X = np.concatenate([X_train, X_test])\n",
        "y = np.concatenate([y_train, y_test])\n",
        "\n",
        "\n",
        "X = X / 225.0\n",
        "\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(y)\n",
        "y = oh_encoder.transform(y[:, 0:1]).toarray()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.15)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n",
        "                                                      y_train,\n",
        "                                                      test_size=0.15)"
      ],
      "metadata": {
        "id": "zSzPRGrzZIwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = k.callbacks.EarlyStopping(restore_best_weights=True,\n",
        "                                                    patience=5)\n",
        "tb_callback = k.callbacks.TensorBoard(f\"tb_logs/cifar10/{datetime.now().strftime('%Y-%m-%d_%H-%M')}\")"
      ],
      "metadata": {
        "id": "F688PlPQoMf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = k.models.Sequential([\n",
        "    k.layers.Flatten(input_shape=X_train.shape[1:]),\n",
        "    k.layers.Dense(200, activation='relu'),\n",
        "    k.layers.Dense(150, activation='relu'),\n",
        "    k.layers.Dense(100, activation='relu'),\n",
        "    k.layers.Dense(75,  activation='relu'),\n",
        "    k.layers.Dense(10,  activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "ReafaNeI1Kzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='sgd',\n",
        "    metrics='accuracy'\n",
        ")"
      ],
      "metadata": {
        "id": "rjfdp7Cs1WIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=210,\n",
        "    validation_data=[X_valid, y_valid],\n",
        "    callbacks = [tb_callback, early_stopping_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf31cpXP1YvG",
        "outputId": "518d35ea-7b33-434a-c6fc-520f30e33050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/210\n",
            "1355/1355 [==============================] - 10s 7ms/step - loss: 1.9418 - accuracy: 0.2926 - val_loss: 1.8313 - val_accuracy: 0.3425\n",
            "Epoch 2/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.7389 - accuracy: 0.3751 - val_loss: 1.7813 - val_accuracy: 0.3643\n",
            "Epoch 3/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.6528 - accuracy: 0.4058 - val_loss: 1.6287 - val_accuracy: 0.4178\n",
            "Epoch 4/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.5977 - accuracy: 0.4286 - val_loss: 1.6674 - val_accuracy: 0.4108\n",
            "Epoch 5/210\n",
            "1355/1355 [==============================] - 8s 6ms/step - loss: 1.5479 - accuracy: 0.4480 - val_loss: 1.6060 - val_accuracy: 0.4268\n",
            "Epoch 6/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.5125 - accuracy: 0.4582 - val_loss: 1.5813 - val_accuracy: 0.4498\n",
            "Epoch 7/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.4735 - accuracy: 0.4746 - val_loss: 1.4988 - val_accuracy: 0.4642\n",
            "Epoch 8/210\n",
            "1355/1355 [==============================] - 10s 8ms/step - loss: 1.4465 - accuracy: 0.4806 - val_loss: 1.5322 - val_accuracy: 0.4550\n",
            "Epoch 9/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.4192 - accuracy: 0.4897 - val_loss: 1.5446 - val_accuracy: 0.4473\n",
            "Epoch 10/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.3902 - accuracy: 0.5039 - val_loss: 1.4544 - val_accuracy: 0.4776\n",
            "Epoch 11/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.3729 - accuracy: 0.5077 - val_loss: 1.5208 - val_accuracy: 0.4573\n",
            "Epoch 12/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.3474 - accuracy: 0.5192 - val_loss: 1.4662 - val_accuracy: 0.4800\n",
            "Epoch 13/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.3285 - accuracy: 0.5276 - val_loss: 1.5905 - val_accuracy: 0.4305\n",
            "Epoch 14/210\n",
            "1355/1355 [==============================] - 10s 7ms/step - loss: 1.3106 - accuracy: 0.5326 - val_loss: 1.5318 - val_accuracy: 0.4790\n",
            "Epoch 15/210\n",
            "1355/1355 [==============================] - 10s 7ms/step - loss: 1.2911 - accuracy: 0.5389 - val_loss: 1.4363 - val_accuracy: 0.4867\n",
            "Epoch 16/210\n",
            "1355/1355 [==============================] - 10s 7ms/step - loss: 1.2741 - accuracy: 0.5453 - val_loss: 1.4944 - val_accuracy: 0.4861\n",
            "Epoch 17/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.2557 - accuracy: 0.5523 - val_loss: 1.4141 - val_accuracy: 0.5018\n",
            "Epoch 18/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.2404 - accuracy: 0.5578 - val_loss: 1.3873 - val_accuracy: 0.5142\n",
            "Epoch 19/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.2224 - accuracy: 0.5612 - val_loss: 1.3821 - val_accuracy: 0.5141\n",
            "Epoch 20/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.2075 - accuracy: 0.5687 - val_loss: 1.4444 - val_accuracy: 0.4933\n",
            "Epoch 21/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.1913 - accuracy: 0.5734 - val_loss: 1.3696 - val_accuracy: 0.5132\n",
            "Epoch 22/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.1755 - accuracy: 0.5794 - val_loss: 1.3824 - val_accuracy: 0.5136\n",
            "Epoch 23/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.1610 - accuracy: 0.5872 - val_loss: 1.4513 - val_accuracy: 0.5035\n",
            "Epoch 24/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.1447 - accuracy: 0.5891 - val_loss: 1.3991 - val_accuracy: 0.5099\n",
            "Epoch 25/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.1320 - accuracy: 0.5954 - val_loss: 1.3579 - val_accuracy: 0.5256\n",
            "Epoch 26/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.1167 - accuracy: 0.6018 - val_loss: 1.4354 - val_accuracy: 0.5025\n",
            "Epoch 27/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.0996 - accuracy: 0.6056 - val_loss: 1.4408 - val_accuracy: 0.4986\n",
            "Epoch 28/210\n",
            "1355/1355 [==============================] - 9s 6ms/step - loss: 1.0883 - accuracy: 0.6110 - val_loss: 1.3701 - val_accuracy: 0.5203\n",
            "Epoch 29/210\n",
            "1355/1355 [==============================] - 10s 7ms/step - loss: 1.0732 - accuracy: 0.6170 - val_loss: 1.3957 - val_accuracy: 0.5159\n",
            "Epoch 30/210\n",
            "1355/1355 [==============================] - 9s 7ms/step - loss: 1.0605 - accuracy: 0.6224 - val_loss: 1.4161 - val_accuracy: 0.5141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback.best_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj1UFZuq1anE",
        "outputId": "ead7df31-b585-431e-9974-da5f4eadf220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.02508067, -0.03334561, -0.02144991, ...,  0.03318071,\n",
              "         -0.02089412, -0.00240068],\n",
              "        [ 0.05648606, -0.02586607,  0.00537451, ..., -0.03598863,\n",
              "          0.00310797,  0.01778275],\n",
              "        [ 0.02382746,  0.04007661,  0.02124556, ..., -0.0012454 ,\n",
              "          0.06983464,  0.01131612],\n",
              "        ...,\n",
              "        [-0.01702288, -0.02329797, -0.02669494, ...,  0.04122135,\n",
              "          0.0288592 ,  0.04205538],\n",
              "        [ 0.0160239 , -0.00739117,  0.01327451, ...,  0.02334978,\n",
              "         -0.01969835,  0.03375249],\n",
              "        [-0.01743956,  0.01891793, -0.00783742, ..., -0.02519464,\n",
              "         -0.01927463,  0.01080537]], dtype=float32),\n",
              " array([-4.95840386e-02, -1.67941395e-03,  1.17058624e-02, -7.44494647e-02,\n",
              "         4.37897304e-03, -3.37684900e-02, -2.72371527e-02,  2.17803735e-02,\n",
              "        -5.83170564e-04, -1.58696160e-01, -3.67166065e-02,  3.80413677e-03,\n",
              "         3.68952230e-02,  8.06835853e-03,  9.70367044e-02,  8.30021352e-02,\n",
              "         3.80439870e-03, -9.21092695e-04, -3.84669378e-02, -2.58114329e-03,\n",
              "         9.99484360e-02, -3.95326652e-02,  4.10797782e-02, -4.56306897e-03,\n",
              "         1.37255648e-02,  2.02217307e-02,  1.45904332e-01, -3.49967740e-02,\n",
              "        -1.76767837e-02, -1.03764934e-02, -1.59774104e-03, -2.36498308e-03,\n",
              "         1.65326688e-02,  3.01400607e-04, -1.97754558e-02,  7.42741069e-03,\n",
              "        -3.72925922e-02,  1.58430859e-01, -1.01184040e-01,  1.80929247e-03,\n",
              "        -8.08569640e-02,  4.28278409e-02,  7.23605044e-03,  3.70299630e-02,\n",
              "         1.97191034e-02, -6.59970418e-02, -6.10641763e-02,  4.61059390e-03,\n",
              "         3.78094986e-02, -5.56609768e-04, -4.14145775e-02, -9.36578661e-02,\n",
              "         8.62220395e-03,  4.69881203e-03, -4.89729457e-03, -6.89147338e-02,\n",
              "         2.62400061e-02,  2.25611806e-01,  1.43131120e-02,  2.43116934e-02,\n",
              "        -1.05630808e-01, -4.82770987e-02,  1.06507223e-02,  4.16507982e-02,\n",
              "        -1.97280347e-02,  1.15246754e-02, -8.19461346e-02, -2.46205833e-02,\n",
              "         2.68881060e-02, -1.45473275e-02, -7.75564054e-04,  2.33229361e-02,\n",
              "        -1.14280611e-01,  5.71410581e-02, -1.76011608e-03,  9.24889930e-03,\n",
              "         2.65509002e-02,  5.53189106e-02,  4.18231031e-03, -5.51178046e-02,\n",
              "        -6.17234968e-02,  4.17177391e-04, -1.42328851e-02,  1.56403482e-02,\n",
              "         7.47860875e-03, -7.61819631e-02, -4.45988728e-03, -1.46460067e-02,\n",
              "        -1.24529703e-03, -2.09158563e-04, -9.18091275e-03, -2.03044317e-03,\n",
              "        -3.48767303e-02, -6.91380724e-02,  9.18644771e-04, -1.66781328e-03,\n",
              "         1.76928174e-02, -2.29692063e-03,  3.62035595e-02,  1.58426166e-02,\n",
              "         5.98809635e-03, -2.02214811e-02, -3.33477510e-03, -1.48369923e-01,\n",
              "        -2.94057594e-04, -1.16593607e-01,  3.09370290e-02,  3.47963609e-02,\n",
              "        -2.07452639e-03, -5.62068969e-02, -9.70976835e-04,  7.56327212e-02,\n",
              "        -9.12343850e-04, -1.82138458e-02,  1.08631942e-02,  1.01184435e-02,\n",
              "         1.41187040e-02, -6.07285760e-02,  8.56551304e-02,  2.86160549e-03,\n",
              "         4.83743846e-04,  1.14315012e-02, -7.66410902e-02, -2.21788716e-02,\n",
              "         8.04218836e-03,  1.26250342e-01,  5.31133972e-02,  1.27046078e-01,\n",
              "         1.52372131e-02, -5.96035388e-04,  1.34742618e-01, -3.10812495e-03,\n",
              "        -3.01452652e-02, -1.43699441e-03, -6.53294697e-02,  2.11415114e-03,\n",
              "         1.22550400e-02, -3.26686981e-03, -4.62955348e-02,  1.99298672e-02,\n",
              "         1.54221337e-02, -7.37307686e-03,  3.54419984e-02, -1.56009033e-01,\n",
              "        -1.35241007e-03,  8.37101042e-02,  4.31775637e-02,  9.59860235e-02,\n",
              "        -7.14163529e-03,  1.80766918e-02, -3.84363718e-02, -1.07480651e-02,\n",
              "         8.33436288e-03,  2.68152356e-03, -5.60625903e-02,  5.89215681e-02,\n",
              "         1.16226375e-02, -1.04613230e-01, -6.85035338e-05,  4.02879715e-02,\n",
              "        -7.32741654e-02,  6.50266744e-03, -7.61797279e-02,  2.32684426e-02,\n",
              "         2.74048541e-02,  7.17548504e-02, -7.28324875e-02,  2.37736339e-03,\n",
              "         4.14469792e-03,  3.78749595e-04, -1.89678371e-03,  5.90003841e-03,\n",
              "         5.39084012e-03,  4.10320088e-02,  6.38091862e-02,  8.10324127e-05,\n",
              "         1.00438736e-01,  1.46488458e-01,  8.91012400e-02,  6.90124184e-03,\n",
              "         1.53208179e-02,  2.63344590e-02, -4.85677533e-02, -1.23327062e-01,\n",
              "         1.16150621e-02,  3.91501654e-03, -2.17507035e-02,  1.44873811e-02,\n",
              "        -1.28435954e-01,  2.28968915e-03,  1.24870792e-01, -4.76897648e-03,\n",
              "        -9.85491276e-02,  1.15399741e-01,  3.37227397e-02,  1.28921270e-01,\n",
              "         1.48468331e-01, -4.46199323e-04, -2.86868066e-02,  1.11403540e-01],\n",
              "       dtype=float32),\n",
              " array([[-0.05481611, -0.09718879, -0.04018178, ..., -0.02297107,\n",
              "          0.09662258,  0.00363619],\n",
              "        [-0.00532945, -0.04672855, -0.05729358, ..., -0.06557129,\n",
              "          0.03401607,  0.03990129],\n",
              "        [-0.0081776 , -0.12300298, -0.01357098, ...,  0.0872454 ,\n",
              "         -0.12451003,  0.02361155],\n",
              "        ...,\n",
              "        [ 0.09211502,  0.02543895,  0.10282314, ...,  0.02531836,\n",
              "          0.03592531,  0.12447122],\n",
              "        [-0.02776753, -0.16543299, -0.07407047, ..., -0.10662604,\n",
              "         -0.11393575, -0.06371087],\n",
              "        [ 0.06282758, -0.09174869, -0.11287528, ..., -0.07574408,\n",
              "          0.09583641, -0.09952912]], dtype=float32),\n",
              " array([-2.95467544e-02, -8.03357661e-02, -9.31733027e-02,  3.79873775e-02,\n",
              "         5.13803177e-02, -1.06805012e-01,  1.97025627e-01,  2.69291606e-02,\n",
              "        -8.86911899e-02,  8.76127742e-03, -7.18500912e-02,  2.73058447e-03,\n",
              "        -1.64311496e-03, -4.68358211e-03, -8.33806619e-02, -5.86206131e-02,\n",
              "        -2.63972348e-03,  6.47859797e-02,  1.60182163e-01, -2.69616693e-02,\n",
              "         4.61027212e-02,  9.12179500e-02, -2.21109986e-01, -1.06389169e-02,\n",
              "         8.44481215e-03, -5.43941893e-02,  3.35470997e-02,  3.82685781e-01,\n",
              "         9.69481543e-02, -4.02227230e-02, -1.69146643e-03,  2.26247963e-02,\n",
              "         1.12323575e-01,  1.27475720e-03, -7.03781052e-03, -2.86485162e-02,\n",
              "        -2.47399583e-02,  9.23955217e-02, -1.38602583e-02, -3.94205749e-02,\n",
              "         1.54492306e-02,  5.63262999e-02, -5.42424917e-02, -4.62502912e-02,\n",
              "         2.04498366e-01, -6.17996342e-02, -9.64352414e-02,  2.90306541e-03,\n",
              "         1.45039529e-01, -3.00035235e-02, -1.62038498e-03, -3.83276194e-02,\n",
              "        -2.64506089e-03,  3.35227996e-02,  2.03998014e-01,  1.02428176e-01,\n",
              "        -2.37393826e-02, -1.81982815e-02, -1.13919787e-01,  1.45286426e-01,\n",
              "         3.47950100e-03,  1.18531562e-01,  1.08313084e-01, -4.04210351e-02,\n",
              "        -3.01466826e-02, -1.48572937e-01, -2.50164350e-03, -5.70206717e-02,\n",
              "         1.25563428e-01, -1.71640478e-02,  7.99140334e-02,  6.81339204e-02,\n",
              "         9.56693590e-02,  1.99746951e-01, -1.03416868e-01, -5.27905785e-02,\n",
              "        -2.71172747e-02,  5.23988008e-02, -3.56419757e-02, -6.58994168e-03,\n",
              "        -1.81870818e-01,  1.97049126e-01, -6.40000850e-02, -4.60043224e-03,\n",
              "         3.99937489e-05, -5.11947321e-03,  4.14008677e-01, -7.97243975e-03,\n",
              "        -1.73525542e-01, -1.07805364e-01, -4.74302061e-02, -4.05898802e-02,\n",
              "         3.47216465e-02, -9.22598913e-02, -1.26109459e-02,  7.15147182e-02,\n",
              "         7.43265226e-02,  4.23216186e-02,  4.44885790e-02, -4.01285812e-02,\n",
              "        -5.72972596e-02,  4.70636413e-02, -3.92587334e-02, -1.09763563e-01,\n",
              "        -6.79291086e-03,  4.10650112e-02, -2.52277285e-01,  7.29803275e-03,\n",
              "        -9.22155976e-02, -3.50537412e-02,  5.26474491e-02,  2.29065362e-02,\n",
              "         5.07153943e-02,  7.63041079e-02,  2.13432666e-02, -1.67377281e-03,\n",
              "        -1.21239992e-02,  8.32733288e-02, -8.36032815e-03,  7.76125342e-02,\n",
              "         7.96374381e-02,  7.09985103e-03, -1.11924373e-02,  8.70436057e-03,\n",
              "         9.14627761e-02,  3.34383594e-03, -7.87584484e-02,  3.20927463e-02,\n",
              "        -5.30716479e-02, -7.77636003e-03, -2.89821997e-03, -9.86247323e-03,\n",
              "         7.42247924e-02,  5.39567694e-02,  1.82659887e-02, -3.87100987e-02,\n",
              "        -2.94786226e-02, -5.83010279e-02,  1.47676051e-01,  2.42689699e-02,\n",
              "         1.43663779e-01, -6.93399273e-03, -1.91078347e-03,  7.13027455e-03,\n",
              "         9.55553055e-02,  5.47714569e-02,  4.59926901e-03,  1.25070254e-03,\n",
              "        -3.02331503e-02, -8.28706324e-02], dtype=float32),\n",
              " array([[ 0.2022559 , -0.09039623, -0.00297335, ..., -0.04277572,\n",
              "         -0.11169797,  0.06107486],\n",
              "        [ 0.04220531, -0.07081073, -0.00997795, ..., -0.03683838,\n",
              "         -0.12259609,  0.09723092],\n",
              "        [ 0.08128241, -0.06537689, -0.13469014, ...,  0.1698827 ,\n",
              "         -0.04382718,  0.04937662],\n",
              "        ...,\n",
              "        [-0.0178815 ,  0.09173381,  0.10911804, ..., -0.01399819,\n",
              "          0.05162155, -0.04472936],\n",
              "        [-0.01800962,  0.13410965,  0.12053076, ..., -0.02674363,\n",
              "          0.02545701,  0.09197827],\n",
              "        [ 0.08845828, -0.04031699, -0.08815607, ...,  0.00451434,\n",
              "         -0.00675374,  0.19954714]], dtype=float32),\n",
              " array([-3.14892121e-02,  4.11834829e-02, -8.58914480e-02,  2.57801190e-02,\n",
              "        -2.71255691e-02,  1.90498009e-01,  1.77265584e-01, -7.30218086e-03,\n",
              "         1.54189616e-01,  9.42734629e-02,  5.25238784e-03, -7.83361644e-02,\n",
              "         1.31767005e-01, -1.38096763e-02, -3.13982659e-04, -9.53384563e-02,\n",
              "         1.62197351e-02,  1.55103728e-01,  2.20256904e-03, -5.43606915e-02,\n",
              "         3.22048932e-01, -5.20538874e-02,  2.26110995e-01, -3.99552174e-02,\n",
              "        -1.04793064e-01, -1.46728642e-02,  1.12501785e-01,  2.22239085e-02,\n",
              "         8.54623541e-02,  4.12372537e-02,  1.31611270e-03, -1.65749192e-01,\n",
              "         1.51314870e-01, -1.44792929e-01, -3.71503532e-02,  4.50224914e-02,\n",
              "        -2.02290602e-02,  5.06836670e-07,  4.37294580e-02, -1.20900245e-03,\n",
              "         1.37684748e-01, -1.72924213e-02, -4.15945984e-03, -1.48983281e-02,\n",
              "         1.38627989e-02,  1.75981037e-03,  2.80599501e-02, -2.24273372e-02,\n",
              "         2.29057714e-01,  3.41970287e-02, -3.12713049e-02,  2.83295959e-02,\n",
              "         1.11298569e-01,  1.82189316e-01,  7.88999069e-03,  1.34229690e-01,\n",
              "        -1.18300552e-02,  6.89896010e-03,  1.97744798e-02, -6.77534863e-02,\n",
              "         5.92481792e-02,  4.98796776e-02,  4.46817353e-02,  8.31712484e-02,\n",
              "         9.61682200e-03, -2.28103809e-02,  6.72787949e-02,  1.17682531e-01,\n",
              "         7.07849339e-02, -2.25778483e-02, -1.14143058e-03,  1.67089492e-01,\n",
              "         1.67781353e-01, -1.46720305e-01,  2.13204790e-02,  2.21174001e-03,\n",
              "        -5.81059325e-03, -3.72889242e-03,  1.91052660e-01, -6.67304769e-02,\n",
              "        -2.36733519e-02,  3.30372900e-02,  1.96084708e-01, -1.12201735e-01,\n",
              "        -2.96561811e-02, -3.95190828e-02,  1.76116079e-02, -2.36970671e-02,\n",
              "        -1.57489907e-02,  1.23098992e-01,  2.14798644e-01,  9.73451138e-02,\n",
              "        -1.00989826e-02, -1.98352084e-01, -1.40537515e-01, -5.56827970e-02,\n",
              "         7.73520619e-02, -7.05020577e-02, -8.63811523e-02, -6.91854907e-03],\n",
              "       dtype=float32),\n",
              " array([[ 0.21621464, -0.03391574, -0.04798906, ..., -0.03870797,\n",
              "         -0.19030188, -0.05268541],\n",
              "        [ 0.04114739,  0.12770014,  0.00580033, ..., -0.18459834,\n",
              "         -0.05907179, -0.02269527],\n",
              "        [ 0.03290959,  0.13025014,  0.12469161, ...,  0.0912054 ,\n",
              "         -0.00768949,  0.05248011],\n",
              "        ...,\n",
              "        [ 0.03818918, -0.23587802,  0.02320015, ...,  0.20304699,\n",
              "         -0.02709054,  0.21436372],\n",
              "        [ 0.23322555, -0.08305978,  0.10601547, ..., -0.00113185,\n",
              "         -0.08736642, -0.11803235],\n",
              "        [-0.19331938,  0.11180505, -0.05764348, ..., -0.1278607 ,\n",
              "          0.1433424 , -0.14347222]], dtype=float32),\n",
              " array([-0.12331372,  0.10416202, -0.02355913,  0.00849383,  0.00212214,\n",
              "         0.2098895 ,  0.21397792,  0.03372417,  0.11354211, -0.00194588,\n",
              "         0.06603882,  0.0155121 ,  0.11793494,  0.03535349,  0.08426557,\n",
              "         0.18726279, -0.1600269 ,  0.09830858, -0.06986011, -0.14967765,\n",
              "        -0.00406076, -0.02194847,  0.0289684 , -0.00496667, -0.03475431,\n",
              "        -0.08093326,  0.04560819, -0.01204568,  0.07432925, -0.00614723,\n",
              "        -0.01698863,  0.01927339,  0.02440155,  0.19577946, -0.01636062,\n",
              "         0.0301425 ,  0.21253729,  0.1403729 , -0.00827057, -0.24329537,\n",
              "        -0.00508246, -0.10276403,  0.02992981, -0.01550752, -0.06763024,\n",
              "         0.04726471, -0.01537524, -0.02606903, -0.01643411,  0.13609858,\n",
              "         0.01087161, -0.02264434, -0.01838125, -0.03033325, -0.0061435 ,\n",
              "         0.04244474, -0.022475  ,  0.08654767,  0.06153446, -0.01800379,\n",
              "         0.07425125, -0.00762942,  0.30602473, -0.09291125,  0.01055286,\n",
              "         0.15248981,  0.20592389, -0.01445737, -0.0411556 ,  0.01255281,\n",
              "         0.10430489,  0.01296672,  0.18361732,  0.09960769, -0.03980635],\n",
              "       dtype=float32),\n",
              " array([[ 3.02332342e-01,  4.30858940e-01, -4.87357602e-02,\n",
              "         -2.09086463e-01, -5.40794851e-03, -7.66637698e-02,\n",
              "         -4.71056819e-01, -2.23790422e-01,  3.76122952e-01,\n",
              "          3.58406663e-01],\n",
              "        [-1.46571621e-01,  1.36205912e-01, -2.39941120e-01,\n",
              "         -1.49993584e-01,  2.32463956e-01,  9.80525315e-02,\n",
              "          1.36840921e-02,  7.19601288e-02,  4.15478885e-01,\n",
              "         -1.56621203e-01],\n",
              "        [ 1.27111584e-01, -1.72940925e-01,  8.07909742e-02,\n",
              "          1.95595995e-01,  2.13292524e-01,  7.68894702e-02,\n",
              "         -1.44431069e-01, -1.96190163e-01,  7.83636868e-02,\n",
              "          1.87366366e-01],\n",
              "        [ 2.35441655e-01, -1.29005313e-01, -1.34992763e-01,\n",
              "          8.58930945e-02,  1.64313436e-01, -7.77380960e-03,\n",
              "          1.19004689e-01, -2.55781800e-01, -1.35770217e-02,\n",
              "          1.17958084e-01],\n",
              "        [-2.43409693e-01, -6.78819343e-02, -1.17420234e-01,\n",
              "         -5.57615049e-02,  5.96445054e-02,  2.68071890e-01,\n",
              "         -5.61168976e-02, -2.53564239e-01, -1.89030334e-01,\n",
              "          1.40051097e-01],\n",
              "        [-2.74180561e-01, -1.44778565e-01,  1.44330233e-01,\n",
              "         -3.21003795e-01,  2.07891703e-01, -1.77706048e-01,\n",
              "         -5.91619033e-03,  4.17474180e-01, -2.77471125e-01,\n",
              "         -3.15692395e-01],\n",
              "        [-2.47610062e-01,  1.03271075e-01,  2.51235276e-01,\n",
              "         -1.89610466e-01,  1.43085206e-02, -1.56856120e-01,\n",
              "          4.99273688e-01,  1.11759761e-02,  8.78715962e-02,\n",
              "          3.75196547e-03],\n",
              "        [ 1.04341999e-01, -2.76123658e-02, -1.87461153e-01,\n",
              "          2.40005299e-01,  4.27317843e-02, -5.12500294e-02,\n",
              "          1.71747237e-01, -2.10423306e-01, -1.44574195e-01,\n",
              "          2.50327915e-01],\n",
              "        [-1.27970889e-01,  2.66784057e-02,  3.27933989e-02,\n",
              "         -2.21570835e-01,  2.27661192e-01, -1.50929332e-01,\n",
              "         -1.11246578e-01,  2.42687836e-01, -2.17279315e-01,\n",
              "          3.04359823e-01],\n",
              "        [ 1.81092527e-02, -6.09238185e-02, -2.44270861e-01,\n",
              "          1.01967342e-01, -1.64322108e-01, -1.57654107e-01,\n",
              "          5.02360575e-02, -3.95411327e-02,  6.27351627e-02,\n",
              "         -1.99071795e-01],\n",
              "        [ 1.53980315e-01,  1.61698535e-01,  2.29207158e-01,\n",
              "         -1.86222568e-01, -1.69281721e-01, -2.20620513e-01,\n",
              "          9.35565829e-02,  2.20735166e-02,  2.17491299e-01,\n",
              "          2.64126748e-01],\n",
              "        [-1.04149297e-01, -2.94982791e-01, -7.47802630e-02,\n",
              "          8.38979408e-02, -2.76822180e-01, -2.37768292e-01,\n",
              "         -2.23915532e-01, -1.85762659e-01,  2.23520085e-01,\n",
              "          1.43170267e-01],\n",
              "        [ 5.47333732e-02, -1.03334159e-01, -1.87809452e-01,\n",
              "          1.66458040e-01,  1.41161218e-01, -2.22792417e-01,\n",
              "          3.02217603e-01, -2.04513848e-01,  8.02929178e-02,\n",
              "         -2.84883678e-02],\n",
              "        [-1.87656194e-01, -1.90769345e-01,  1.24350175e-01,\n",
              "         -1.42635033e-01, -2.92321146e-01,  1.95138514e-01,\n",
              "          1.24996550e-01, -2.73077846e-01, -8.59445333e-02,\n",
              "          1.76095348e-02],\n",
              "        [-2.49543265e-01,  1.50759175e-01, -3.10296472e-02,\n",
              "         -2.59658605e-01, -3.47723216e-01, -3.09295595e-01,\n",
              "          7.80250058e-02, -2.08590999e-01, -2.70329490e-02,\n",
              "          5.01608729e-01],\n",
              "        [ 2.76094317e-01,  8.35948437e-02,  5.34870446e-01,\n",
              "         -2.60704964e-01,  3.47099751e-01, -3.95741880e-01,\n",
              "          7.35331625e-02, -3.42568383e-02, -2.01920107e-01,\n",
              "          3.44306901e-02],\n",
              "        [ 3.12565058e-01, -3.51153374e-01, -4.11988376e-03,\n",
              "         -6.75698295e-02,  9.20016468e-02,  2.65295446e-01,\n",
              "         -3.48604321e-01,  2.23932222e-01, -4.34648156e-01,\n",
              "          1.12936899e-01],\n",
              "        [ 1.12828128e-01, -4.02293593e-01,  5.98763712e-02,\n",
              "         -5.08125834e-02,  5.23389392e-02,  2.37464920e-01,\n",
              "          2.26012215e-01, -1.32794619e-01,  1.00598969e-01,\n",
              "         -2.12835267e-01],\n",
              "        [ 6.32540882e-02, -1.50393590e-01,  2.84296364e-01,\n",
              "          1.13322191e-01, -2.16187581e-01,  3.18382949e-01,\n",
              "          8.73203799e-02, -2.55284429e-01,  2.73888141e-01,\n",
              "         -1.52749553e-01],\n",
              "        [ 1.48553804e-01, -1.11446254e-01, -3.57789010e-01,\n",
              "         -3.81695107e-02, -3.09301049e-01, -2.80657470e-01,\n",
              "         -3.31374586e-01,  2.26410478e-02,  2.33108655e-01,\n",
              "          2.44186282e-01],\n",
              "        [ 3.33311521e-02, -1.92692280e-01,  2.21426278e-01,\n",
              "         -2.16772094e-01,  1.91062734e-01, -2.02786416e-01,\n",
              "          7.92473927e-02,  8.56079832e-02, -1.71075970e-01,\n",
              "         -8.62273648e-02],\n",
              "        [-1.57941818e-01,  2.96985675e-02, -2.07953334e-01,\n",
              "          2.47203752e-01, -2.38479245e-02, -1.00506656e-01,\n",
              "         -5.95196411e-02,  1.30860522e-01, -6.69447184e-02,\n",
              "          2.20607623e-01],\n",
              "        [ 3.50013435e-01,  2.05632998e-03, -1.23672321e-01,\n",
              "         -1.62353516e-01,  7.30043799e-02, -1.29444033e-01,\n",
              "         -9.86605361e-02, -2.87642837e-01,  1.09373026e-01,\n",
              "         -1.53012931e-01],\n",
              "        [-2.62006342e-01,  1.19129345e-01,  9.82974097e-02,\n",
              "          1.50899053e-01, -2.06567273e-01, -2.86707222e-01,\n",
              "         -2.27919653e-01,  1.60115153e-01, -1.09584570e-01,\n",
              "          2.16588557e-01],\n",
              "        [ 1.97986811e-01,  2.51186401e-01, -2.83944327e-02,\n",
              "          1.03494838e-01, -2.39269752e-02, -2.73622442e-02,\n",
              "         -9.24521983e-02, -8.65722001e-02, -2.65155792e-01,\n",
              "          2.75347054e-01],\n",
              "        [ 4.56849009e-01, -1.36028871e-01,  1.99998766e-01,\n",
              "         -1.23149551e-01, -8.76942649e-02,  5.39203249e-02,\n",
              "         -3.66865993e-01, -2.86138177e-01,  2.24410743e-01,\n",
              "         -2.85181910e-01],\n",
              "        [ 8.41553137e-02, -2.03678325e-01,  2.77510792e-01,\n",
              "         -6.98896572e-02,  2.00701669e-01,  9.03898031e-02,\n",
              "         -1.15818195e-01, -3.02250534e-01,  2.30471417e-01,\n",
              "          1.58993796e-01],\n",
              "        [-3.87671008e-03, -9.26980004e-02, -1.39032649e-02,\n",
              "         -2.07265154e-01, -1.10542819e-01, -1.94393441e-01,\n",
              "         -1.10861883e-01, -2.24581033e-01,  2.33350322e-01,\n",
              "         -3.85518335e-02],\n",
              "        [ 3.55897307e-01,  9.02446080e-03,  3.27011079e-01,\n",
              "          7.77690634e-02,  1.76695392e-01, -2.07987711e-01,\n",
              "         -2.02998742e-01, -3.64722282e-01,  1.16256699e-01,\n",
              "         -1.69333741e-02],\n",
              "        [ 1.95458502e-01, -6.07678965e-02, -1.89983830e-01,\n",
              "          2.37716381e-02,  5.57660498e-02, -1.88577041e-01,\n",
              "         -2.59749386e-02,  1.34989813e-01, -2.57787883e-01,\n",
              "          2.45142713e-01],\n",
              "        [-7.68820196e-02, -1.72146812e-01,  1.88254923e-01,\n",
              "          2.61212587e-01, -5.58621548e-02, -1.08209446e-01,\n",
              "         -4.72516008e-02, -1.90794110e-01, -2.71217465e-01,\n",
              "         -2.27546796e-01],\n",
              "        [ 2.29240179e-01,  1.73095196e-01, -6.26137331e-02,\n",
              "          1.62078753e-01, -9.67753232e-02, -1.82651252e-01,\n",
              "          2.42902085e-01, -1.12690568e-01,  7.57069066e-02,\n",
              "         -1.41615480e-01],\n",
              "        [-3.01605493e-01,  1.01653405e-01, -2.32592076e-02,\n",
              "         -6.94570467e-02,  1.00420471e-02,  3.20374459e-01,\n",
              "         -1.73087157e-02, -3.48288149e-01, -2.64474928e-01,\n",
              "         -7.58470297e-02],\n",
              "        [-2.37530082e-01, -2.99830467e-01,  4.91726249e-01,\n",
              "          6.48339018e-02, -1.22776486e-01, -1.47129998e-01,\n",
              "          2.16299500e-02, -3.85691077e-01, -1.80755243e-01,\n",
              "         -1.04176633e-01],\n",
              "        [-3.36122066e-01,  2.04005986e-01,  1.31307900e-01,\n",
              "          1.93847224e-01,  3.95232849e-02,  7.49995112e-02,\n",
              "         -1.69751972e-01, -3.11476916e-01,  1.97718143e-01,\n",
              "          1.84442803e-01],\n",
              "        [ 1.15755729e-01, -1.62894223e-02,  2.24601761e-01,\n",
              "         -2.87741065e-01, -1.73475116e-01, -1.20655276e-01,\n",
              "          1.31867915e-01,  1.67222261e-01,  2.03340605e-01,\n",
              "          5.72307631e-02],\n",
              "        [-2.50658184e-01,  2.48264089e-01, -1.84946693e-02,\n",
              "          2.44423181e-01,  2.08166480e-01,  3.61983143e-02,\n",
              "          2.56392032e-01, -2.29764685e-01,  3.19963932e-01,\n",
              "         -2.84666002e-01],\n",
              "        [-9.25820246e-02, -3.04429621e-01, -1.77586958e-01,\n",
              "          2.72297859e-01,  1.22825421e-01,  4.34546638e-03,\n",
              "          1.52822331e-01, -1.64829463e-01, -3.90089989e-01,\n",
              "         -5.32362089e-02],\n",
              "        [ 1.02691226e-01, -9.84254945e-03,  3.23600732e-02,\n",
              "         -1.53947309e-01, -1.66514903e-01, -2.87508249e-01,\n",
              "         -4.04167771e-01,  1.61354169e-01, -9.67587382e-02,\n",
              "         -2.17909232e-01],\n",
              "        [ 7.63243139e-02,  2.15534344e-02, -5.65337278e-02,\n",
              "         -2.91202635e-01, -2.78201163e-01,  1.88138664e-01,\n",
              "         -3.98037285e-01,  3.04622948e-01, -1.85023576e-01,\n",
              "          2.13981137e-01],\n",
              "        [ 4.03296426e-02,  2.16098428e-01, -6.21744394e-02,\n",
              "          7.67093301e-02,  6.15610890e-02,  1.68890625e-01,\n",
              "          7.21998140e-02,  3.20979357e-02, -1.28104091e-01,\n",
              "          2.32362017e-01],\n",
              "        [-7.34123588e-02,  2.08725870e-01,  1.46988899e-01,\n",
              "         -6.43055141e-02, -5.13641894e-01,  3.33287388e-01,\n",
              "         -3.90556045e-02, -1.02927104e-01, -2.38190755e-01,\n",
              "          1.01244777e-01],\n",
              "        [-4.22230698e-02, -9.42543373e-02,  1.47948071e-01,\n",
              "          2.21339613e-01,  2.95354761e-02, -3.88958529e-02,\n",
              "         -7.92788062e-03, -1.48801133e-01,  5.91888558e-03,\n",
              "         -2.81566773e-02],\n",
              "        [-3.98990102e-02, -1.16775796e-01, -2.92357989e-02,\n",
              "          4.59513701e-02,  1.29390687e-01,  1.34293199e-01,\n",
              "         -8.77953246e-02, -5.22378422e-02,  2.07869545e-01,\n",
              "         -1.36671200e-01],\n",
              "        [-2.17003059e-02,  2.52574595e-04,  1.16737504e-02,\n",
              "         -4.57843989e-02, -3.40154797e-01,  9.07210037e-02,\n",
              "         -3.06229502e-01,  3.78483057e-01, -1.18770644e-01,\n",
              "         -2.83522576e-01],\n",
              "        [ 1.87107682e-01, -2.11929172e-01, -1.58159956e-01,\n",
              "         -2.83040432e-03,  1.00387841e-01,  5.99206164e-02,\n",
              "         -2.42469147e-01,  1.54105693e-01, -2.44124364e-02,\n",
              "          1.00844711e-01],\n",
              "        [-1.81614608e-01,  1.39136523e-01, -3.79553176e-02,\n",
              "         -2.49270126e-01,  7.08336979e-02,  6.31735250e-02,\n",
              "         -1.93213504e-02, -7.93640390e-02,  2.04191402e-01,\n",
              "          5.74905872e-02],\n",
              "        [ 6.68457150e-02, -2.43087813e-01, -1.83443606e-01,\n",
              "         -1.25976279e-01, -6.99273273e-02, -2.45472223e-01,\n",
              "         -3.52644473e-01,  4.42273706e-01, -2.06405204e-02,\n",
              "         -2.40041092e-01],\n",
              "        [-3.92682910e-01,  3.73366028e-01, -2.71676034e-01,\n",
              "          2.06561118e-01, -1.24666333e-01,  1.48739479e-02,\n",
              "         -2.46269628e-01,  4.34093885e-02,  3.74073237e-02,\n",
              "          1.96372300e-01],\n",
              "        [-1.48421586e-01, -1.80387929e-01, -1.21186639e-03,\n",
              "         -1.89807907e-01,  3.42006385e-01, -1.81397930e-01,\n",
              "         -2.40817934e-01, -3.21423858e-01, -1.34150594e-01,\n",
              "         -1.08342692e-01],\n",
              "        [ 1.91393971e-01,  1.26426682e-01, -8.23315531e-02,\n",
              "         -4.17440161e-02,  2.51321763e-01,  4.08898070e-02,\n",
              "          4.41536456e-02, -1.04775637e-01, -1.23134449e-01,\n",
              "         -7.68842176e-03],\n",
              "        [ 2.96997190e-01, -8.16570893e-02,  2.95375679e-02,\n",
              "         -8.20838362e-02, -1.03954852e-01,  2.50046074e-01,\n",
              "          7.91781768e-03,  2.11612046e-01, -1.31375790e-01,\n",
              "         -6.75774887e-02],\n",
              "        [-1.40563846e-01, -1.06563687e-01, -1.90844014e-01,\n",
              "         -1.94034085e-01, -7.75248781e-02,  7.80473873e-02,\n",
              "         -8.90554190e-02,  2.31995061e-01,  2.14831218e-01,\n",
              "         -2.23515123e-01],\n",
              "        [ 3.50355744e-01,  3.72125536e-01, -3.02961320e-01,\n",
              "         -1.19156688e-01, -3.10511500e-01, -1.23661481e-01,\n",
              "         -1.39159828e-01,  2.17221692e-01, -1.71088055e-01,\n",
              "         -3.03127766e-01],\n",
              "        [ 2.44658157e-01,  1.78676218e-01,  2.64486670e-02,\n",
              "         -1.86603099e-01, -1.67343263e-02,  1.85744017e-01,\n",
              "          2.27279916e-01, -1.77320257e-01, -1.10936478e-01,\n",
              "         -1.56913519e-01],\n",
              "        [ 2.94379685e-02, -1.79626405e-01, -2.04741701e-01,\n",
              "          1.93412289e-01, -3.24660748e-01,  2.13387012e-01,\n",
              "          4.50062841e-01, -1.91699967e-01, -2.84637094e-01,\n",
              "         -5.92061877e-02],\n",
              "        [ 2.09767804e-01, -2.80431230e-02,  1.83501989e-01,\n",
              "         -1.77188255e-02, -2.51102835e-01, -2.44852334e-01,\n",
              "          2.91537195e-01, -8.09962898e-02,  2.19946146e-01,\n",
              "          1.71552360e-01],\n",
              "        [ 1.46559009e-03,  2.39716664e-01, -3.20804715e-01,\n",
              "         -1.88073084e-01, -1.49788782e-01, -1.98593631e-01,\n",
              "          3.11104029e-01, -1.82491150e-02, -3.57872903e-01,\n",
              "         -5.87317422e-02],\n",
              "        [-2.50056475e-01,  3.03723752e-01, -1.27050564e-01,\n",
              "          6.88832477e-02,  2.32290134e-01,  6.95483536e-02,\n",
              "         -5.55333830e-02,  1.67977974e-01,  4.52580675e-02,\n",
              "          1.22404315e-01],\n",
              "        [ 1.85783669e-01, -9.89160463e-02,  2.16581315e-01,\n",
              "          3.93409789e-01, -2.28498966e-01,  3.58412296e-01,\n",
              "          2.66723543e-01,  4.28399473e-01, -1.27278477e-01,\n",
              "         -4.14635539e-01],\n",
              "        [-3.82900774e-03, -1.88440576e-01, -1.88848943e-01,\n",
              "          1.22787863e-01,  2.92429060e-01,  7.89105743e-02,\n",
              "         -1.24549508e-01,  1.21529013e-01,  1.44689694e-01,\n",
              "         -2.96820462e-01],\n",
              "        [-1.22954309e-01,  2.71529645e-01, -1.61025569e-01,\n",
              "          2.73471158e-02, -1.89019367e-01,  5.94170876e-02,\n",
              "         -2.05901727e-01,  4.61124256e-03,  5.68392016e-02,\n",
              "         -1.38736917e-02],\n",
              "        [ 1.09073175e-02, -4.60021377e-01, -3.80702280e-02,\n",
              "         -1.34211844e-02,  5.44480920e-01, -8.95519927e-02,\n",
              "          4.02904838e-01,  3.24111104e-01, -7.44110793e-02,\n",
              "         -4.88005988e-02],\n",
              "        [-2.67342716e-01, -9.90534648e-02, -3.34682077e-01,\n",
              "         -1.37115210e-01, -1.16736554e-02,  1.55911878e-01,\n",
              "         -2.10883409e-01,  1.50494546e-01,  2.11698055e-01,\n",
              "          4.76039141e-01],\n",
              "        [-1.85442135e-01, -1.53507948e-01, -7.83353448e-02,\n",
              "         -1.97050974e-01,  7.64628127e-02, -3.19986314e-01,\n",
              "         -2.50970069e-02,  2.79745162e-01,  3.13067019e-01,\n",
              "          2.98966974e-01],\n",
              "        [ 2.42192894e-01, -7.49518722e-02,  2.55472600e-01,\n",
              "          1.19547009e-01,  1.11916043e-01,  6.46346658e-02,\n",
              "          3.81800950e-01, -2.13059425e-01, -1.79782689e-01,\n",
              "         -2.12032884e-01],\n",
              "        [-1.09344639e-01, -8.08336586e-02,  3.60163540e-01,\n",
              "          2.49017868e-02,  2.46598691e-01,  1.76130205e-01,\n",
              "          3.54017973e-01,  4.89993729e-02, -8.91198665e-02,\n",
              "         -4.58770543e-01],\n",
              "        [ 3.03694811e-02,  2.50046343e-01, -1.67851776e-01,\n",
              "          2.21298575e-01,  1.95709556e-01, -2.62123019e-01,\n",
              "         -1.46769747e-01,  7.70134255e-02,  9.33146626e-02,\n",
              "          2.27316767e-01],\n",
              "        [-1.80004612e-01,  7.70313665e-02, -3.45588833e-01,\n",
              "          5.47984838e-02, -2.79597849e-01,  3.25004697e-01,\n",
              "          2.94064313e-01, -2.50982612e-01,  3.03138375e-01,\n",
              "         -1.62520871e-01],\n",
              "        [-2.48196587e-01, -3.72366309e-01,  1.66290596e-01,\n",
              "          3.82896841e-01,  2.67949775e-02,  2.12753981e-01,\n",
              "         -2.70365268e-01,  1.70657039e-01, -1.12409063e-01,\n",
              "          5.90187572e-02],\n",
              "        [ 1.39948964e-01,  5.07312655e-01, -2.12358564e-01,\n",
              "         -1.40226454e-01,  1.16345070e-01, -4.06738520e-01,\n",
              "          1.69115931e-01, -1.75804123e-01,  2.33754262e-01,\n",
              "          1.26647130e-01],\n",
              "        [-1.44928977e-01,  2.62641516e-02,  3.17215592e-01,\n",
              "         -2.13347092e-01, -1.16404243e-01, -2.69160628e-01,\n",
              "          6.36655539e-02, -1.60804942e-01,  2.29545683e-01,\n",
              "         -1.36876658e-01],\n",
              "        [-3.57211381e-01,  1.87009797e-01,  3.74023288e-01,\n",
              "          1.85250819e-01,  3.49537224e-01,  2.30670303e-01,\n",
              "         -1.13328047e-01,  6.90549165e-02, -3.40086401e-01,\n",
              "         -1.21980064e-01],\n",
              "        [-3.09283376e-01, -4.29552142e-03,  1.57329589e-01,\n",
              "         -2.95422245e-02,  1.28128514e-01,  1.61747903e-01,\n",
              "         -3.31401408e-01,  2.43877638e-02, -5.73306121e-02,\n",
              "          1.88973736e-05],\n",
              "        [ 1.84948534e-01, -5.53123355e-02,  2.14593679e-01,\n",
              "         -4.19596285e-02,  8.10316876e-02, -1.58396974e-01,\n",
              "         -1.05715446e-01,  1.48494259e-01, -1.78971052e-01,\n",
              "          2.80182391e-01]], dtype=float32),\n",
              " array([-0.29576546, -0.05847301,  0.13512634,  0.04942596,  0.36706698,\n",
              "        -0.32313585,  0.3324196 , -0.02389503, -0.06532335, -0.11744572],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV7No_SitLuN",
        "outputId": "d5020342-edf5-47b8-dc13-3b26764aa06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3579026460647583"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "OMBaTKo2tU2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WgbmVgAyckbv",
        "outputId": "2bd0d415-fef2-43f7-ca81-257289bd79a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "-iOE3edjcr7Y",
        "outputId": "b4dc158f-20c7-443c-f5dd-3ab1a6c73b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuEu-DAdcxpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}